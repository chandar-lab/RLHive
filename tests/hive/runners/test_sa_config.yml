# General training loop config
name: 'SingleAgentRunner'
kwargs:
  experiment_manager:
    name: 'Experiment'
    kwargs:
      name: &run_name 'cartpole-dqn'
      save_dir: 'experiment'
      saving_schedule:
        name: 'PeriodicSchedule'
        kwargs:
          off_value: False
          on_value: True
          period: 15000
  train_steps: 450
  test_frequency: 10
  test_episodes: 1

  # Environment config
  environment:
    name: 'GymEnv'
    kwargs:
      env_name: 'CartPole-v0'

  # List of agents for the experiment. In single agent, only the first agent in
  # the list is used.
  agent:
    name: 'DQNAgent'
    kwargs:
      representation_net:
        name: 'MLPNetwork'
        kwargs:
          hidden_units: [256, 256]
      optimizer_fn:
        name: 'Adam'
        kwargs: {}
      id: 0
      replay_buffer:
        name: 'CircularReplayBuffer'
        kwargs:
          capacity: 10000
      discount_rate: .99
      target_net_update_schedule:
        name: 'PeriodicSchedule'
        kwargs:
          off_value: False
          on_value: True
          period: 100
      epsilon_schedule:
        name: 'ConstantSchedule'
        kwargs:
          value: .01
      min_replay_history: 500
      batch_size: 128
      device: 'cpu'
      log_frequency: 100

  # List of logger configs used.
  loggers:
    -
      name: FakeLogger1
    -
      name: FakeLogger2
      kwargs:
        arg2: .5

