# General training loop config
run_name: &run_name 'cartpole-dqn'
train_steps: 30000
test_frequency: 10
test_num_episodes: 1
saving_schedule:
  name: 'PeriodicSchedule'
  kwargs:
    off_value: False
    on_value: True
    period: 15000
save_dir: 'experiment'

# Environment config
environment:
  name: 'GymEnv'
  kwargs:
    env_name: 'CartPole-v0'

# List of agents for the experiment. In single agent, only the first agent in
# the list is used.
agents: 
  - 
    name: 'RainbowDQNAgent'
    kwargs:
      qnet:
        name: 'RainbowMLP'
        kwargs: 
          hidden_units: 256
          num_hidden_layers: 2
      optimizer_fn:
        name: 'Adam'
        kwargs: {}
      id: 0
      replay_buffer:
        name: 'CircularReplayBuffer'
        kwargs:
          seed: 42
          size: 10000
      discount_rate: .99
      target_net_update_schedule:
        name: 'PeriodicSchedule'
        kwargs:
          off_value: False
          on_value: True
          period: 100
      epsilon_schedule:
        name: 'ConstantSchedule'
        kwargs:
          value: .01
      learn_schedule:
        name: 'SwitchSchedule'
        kwargs:
          off_value: False
          on_value: True
          steps: 500
      seed: 42
      batch_size: 128
      device: 'cpu'
      log_frequency: 100
      double: False
      dueling: True
      distributional: True
      noisy: True
      v_min: -10
      v_max: 10
      atoms: 51

# List of logger configs used.
loggers:
  -
    name: ChompLogger
    kwargs: {}
  -
    name: WandbLogger
    kwargs:
      project_name: Hive-v1
      run_name: *run_name
      offline: False
