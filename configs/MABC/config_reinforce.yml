# General training loop config
run_name: &run_name 'MABC'
train_steps: 500000
test_frequency: 2
test_num_episodes: 2
self_play: False
staged_learning: False
num_agents: 2
stack_size: &stack_size 3
saving_schedule:
  name: 'PeriodicSchedule'
  kwargs:
    off_value: False
    on_value: True
    period: 15000
save_dir: &save_dir 'experiment'

# Environment config
environment:
  name: 'MultiAgentDiscEnv'
  kwargs:
    env_name: 'MABC-v0'
    num_players: 2
    seed: 42

# List of agents for the experiment. In single agent, only the first agent in
# the list is used.
agents:
  -
    name: 'REINFORCEAgent'
    kwargs:
      qnet:
        name: 'DiscObsSimpleMLP'
        kwargs:
          hidden_units: 256
          num_hidden_layers: 2
      optimizer_fn:
        name: 'Adam'
        kwargs:
          lr: 0.00001
      id: 0
      discount_rate: .9
      seed: 42
      device: 'cpu'
      stack_size: *stack_size
  -
    name: 'REINFORCEAgent'
    kwargs:
      qnet:
        name: 'DiscObsSimpleMLP'
        kwargs:
          hidden_units: 256
          num_hidden_layers: 2
      optimizer_fn:
        name: 'Adam'
        kwargs:
          lr: 0.00001
      id: 1
      discount_rate: .9
      seed: 43
      device: 'cpu'
      stack_size: *stack_size

# List of logger configs used.
loggers:
  -
    name: WandbLogger
    kwargs:
      project_name: Hive-v1
      run_name: *run_name
      save_dir: *save_dir
      offline: True