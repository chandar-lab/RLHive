name: 'SingleAgentRunner'
kwargs:
  experiment_manager:
    name: 'Experiment'
    kwargs:
      name: &run_name 'mujoco-ppo'
      save_dir: 'experiment'
      saving_schedule:
        name: 'PeriodicSchedule'
        kwargs:
          off_value: False
          on_value: True
          period: 500000

  train_steps: 2000000
  test_frequency: 10000
  test_episodes: 5
  max_steps_per_episode: 100000
  stack_size: &stack_size 1
  environment:
    name: 'GymEnv'
    kwargs:
      env_name: 'Hopper-v4'
      env_wrappers:
        -
          name: 'ClipAction'
    
  agent:
    name: 'PPOAgent'
    kwargs:
      actor_net:
        name: 'MLPNetwork'
        kwargs: 
          hidden_units: [64, 64]
          activation_fn:
            name: 'Tanh'
      critic_net:
        name: 'MLPNetwork'
        kwargs: 
          hidden_units: [64, 64]
      observation_normalization_fn:
        name: 'ObservationNormalization'
        kwargs:
          clip: 10
      reward_normalization_fn:
        name: 'RewardNormalization'
        kwargs:
          clip: 10
      replay_buffer:
        name: 'OnPolicyReplayBuffer'
        kwargs:
          compute_advantage_fn:
            name: "ComputeGAEAdvantages"
            kwargs:
              gae_lambda: 0.95

      optimizer_fn:
        name: 'Adam'
        kwargs:
          lr: .0003
      discount_rate: .99
      grad_clip: .5
      clip_coefficient: .2
      entropy_coefficient: .0
      clip_value_loss: True
      value_fn_coefficient: .5
      transitions_per_update: 2048
      num_epochs_per_update: 10
      normalize_advantages: True
      batch_size: 64
      device: 'cuda'
      id: 'agent'
      init_fn: 
        name: 'orthogonal'

  # List of logger configs used.
  loggers:
    -
      name: ChompLogger
    -
      name: WandbLogger
      kwargs:
        project: Hive
        name: *run_name
        resume: "allow"
        start_method: "fork"
