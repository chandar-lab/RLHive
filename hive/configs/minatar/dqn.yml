# General training loop config
run_name: &run_name 'breakout-dqn'
train_steps: 10000000
test_frequency: 1000000
max_steps_per_episode: 10000000
test_episodes: 10
saving_schedule:
  name: 'PeriodicSchedule'
  kwargs:
    off_value: False
    on_value: True
    period: 1000000
save_dir: 'experiment'

# Environment config
environment:
  name: 'MinAtarEnv'
  kwargs:
    env_name: 'breakout'

# Agent config
agent:
  name: 'DQNAgent'
  kwargs:
    representation_net:
      name: 'ConvNetwork'
      kwargs:
        channels: [16]
        mlp_layers: [128]
        kernel_sizes: [3]
        strides: [1]
        paddings: [0]
        normalization_factor: 1
    optimizer_fn:
      name: 'Adam'
      kwargs:
        lr: 0.00025
        eps: 0.0003125
    loss_fn:
      name: 'SmoothL1Loss'
    init_fn:
      name: "variance_scaling"
    id: 0
    reward_clip: 1.0
    replay_buffer:
      name: 'CircularReplayBuffer'
      kwargs:
        capacity: 100000
        stack_size: 1
    discount_rate: .99
    update_period_schedule:
      name: 'PeriodicSchedule'
      kwargs:
        off_value: False
        on_value: True
        period: 4
    target_net_update_schedule:
      name: 'PeriodicSchedule'
      kwargs:
        off_value: False
        on_value: True
        period: 1000
    epsilon_schedule:
      name: 'LinearSchedule'
      kwargs:
        init_value: 1
        end_value: 0.01
        steps: 250000
    test_epsilon: .01
    min_replay_history: 1000
    batch_size: 32
    device: 'cuda'
    log_frequency: 1000

# List of logger configs used.
loggers:
  -
    name: ChompLogger
    kwargs: {}
  -
    name: WandbLogger
    kwargs:
      project: Hive
      name: *run_name
      resume: "allow"
      start_method: "fork"
