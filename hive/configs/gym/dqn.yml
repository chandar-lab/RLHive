name: 'SingleAgentRunner'
kwargs:
  experiment_manager:
    name: 'Experiment'
    kwargs:
      name: &run_name 'gym-dqn'
      save_dir: 'experiment'
      saving_schedule:
        name: 'PeriodicSchedule'
        kwargs:
          off_value: False
          on_value: True
          period: 10000
  train_steps: 50000
  test_frequency: 200
  test_episodes: 10
  max_steps_per_episode: 1000
  environment:
    name: 'GymEnv'
    kwargs:
      env_name: 'CartPole-v0'
  agent:
    name: 'DQNAgent'
    kwargs:
      representation_net:
        name: 'MLPNetwork'
        kwargs:
          hidden_units: [256, 256]
      stack_size: 1
      optimizer_fn:
        name: 'Adam'
        kwargs: {}
      loss_fn:
        name: 'SmoothL1Loss'
      replay_buffer:
        name: 'CircularReplayBuffer'
        kwargs:
          capacity: 1000
      discount_rate: .99
      reward_clip: 1
      target_net_update_schedule:
        name: 'PeriodicSchedule'
        kwargs:
          off_value: False
          on_value: True
          period: 100
      update_period_schedule:
        name: 'PeriodicSchedule'
        kwargs:
          off_value: False
          on_value: True
          period: 1
      epsilon_schedule:
        name: 'ConstantSchedule'
        kwargs:
          value: .1
      test_epsilon: .001
      min_replay_history: 500
      device: 'cuda'
      batch_size: 128
      log_frequency: 100
  loggers:
    -
      name: ChompLogger
    -
      name: WandbLogger
      kwargs:
        project: Hive
        name: *run_name
        resume: "allow"
        start_method: "fork"
